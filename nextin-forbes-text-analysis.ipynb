{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "72345ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.collocations import *\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be929ed",
   "metadata": {},
   "source": [
    "## Subcorpus 1: The complete works of William Shakespeare\n",
    "\n",
    "The text is downloaded in .txt format from archive.org: \n",
    "https://archive.org/details/completeworksofw00shakrich\n",
    "\n",
    "The file is truncated to include only the first 9,848 lines because we have slow laptops. :-("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b5abc45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text\n",
    "shakespeareFile = open(\"data/literature-shakespeare-trunc.txt\", \"r\")\n",
    "shakespeareText = shakespeareFile.read()\n",
    "shakespeareTokenized = word_tokenize(shakespeareText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23209c",
   "metadata": {},
   "source": [
    "1. The length (in words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8ff594d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49495\n"
     ]
    }
   ],
   "source": [
    "shakespeareTokens = len(shakespeareTokenized)\n",
    "print(shakespeareTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe18df3",
   "metadata": {},
   "source": [
    "2. The lexical diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5e58dbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13181129407010808\n"
     ]
    }
   ],
   "source": [
    "shakespeareTypes = len(set(shakespeareTokenized))\n",
    "shakespeareLexDiversity = shakespeareTypes / shakespeareTokens\n",
    "print(shakespeareLexDiversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c908eb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "3. The longest sentence (type the sentence and also give the number of words). Hint: look at the Gutenberg part of Section 2.1 in NLTK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "22c95bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest 'sentence' is:\n",
      "\n",
      "\n",
      "Pro, Ye elves of hills, brooks, standing lakes, \n",
      "and groves; \n",
      "\n",
      "And ye that on, the sands with printless foot \n",
      "Do chase the ebbing Neptune, and do fly him \n",
      "When he comes back; you demi-puppets that \n",
      "By moonshine do the green sour ringlets make, \n",
      "Whereoftkeewenotbites;andyouwhosepastime \n",
      "Is to make midnight mushrooms, that rejoice \n",
      "To hear the solemn curfew; by whose aid, — \n",
      "Weak masters thou^ ye be,— I haVe bedimm’d \n",
      "Thenoontidesun,call’dforththemutinous winds, \n",
      "And ’twixt the green sea and the azured vault \n",
      "Set roaring war: to the dread rattling thunder \n",
      "Have I given fire, and rifted Jove’s stout oak \n",
      "With his own bolt: the strong-based promontory \n",
      "Have I made shake: and by the spurs pluck’d up \n",
      "The pine and cedar: graves, at my command, \n",
      "Have waked their sleepers, oped, and let them \n",
      "forth \n",
      "\n",
      "By my so potent art.\n",
      "\n",
      "\n",
      "\n",
      "The sentence has 173 words.\n"
     ]
    }
   ],
   "source": [
    "shakespeareSentences = nltk.sent_tokenize(shakespeareText)\n",
    "word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "print(\"The longest 'sentence' is:\\n\\n\")\n",
    "shakespeareLongestSentence = max(shakespeareSentences, key=word_count)\n",
    "print(shakespeareLongestSentence)\n",
    "print(\"\\n\\n\")\n",
    "print(f\"The sentence has {word_count(shakespeareLongestSentence)} words.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ce2c7",
   "metadata": {},
   "source": [
    "\n",
    "4. The top collocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "18f20798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWO GENTLEMEN; thou art; Sir Proteus; thou hast; Sir Thurio; thou\n",
      "canst; Scene I.—; Sir Valentine; Sir John; Master Page; thou beest;\n",
      "widow Dido; Thou liest; Wilt thou; pray thee; PERSONS REPRESENTED;\n",
      "Pro- teus; John Falstaff; Thou hast; Dost thou\n"
     ]
    }
   ],
   "source": [
    "shakespeareNLTKText = nltk.Text(shakespeareTokenized)\n",
    "shakespeareNLTKText.collocations(num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42092de9",
   "metadata": {},
   "source": [
    "5. The top ten words that start with each of the vowels (involves using FreqDist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e95d9cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten words with 'a': ['and', 'a', 'And', 'as', 'are', 'all', 'at', 'am', 'A', 'Ant']\n",
      "\n",
      "Top ten words with 'e': ['Enter', 'else', 'Exit', 'er', 'Exeunt', 'ever', 'eyes', 'earth', 'even', 'end']\n",
      "\n",
      "Top ten words with 'i': ['I', 'is', 'in', 'it', 'if', 'If', 'It', 'Is', 'In', 'indeed']\n",
      "\n",
      "Top ten words with 'o': ['of', 'on', 'one', 'our', 'or', 'out', 'Out', 'Of', 'O', 'own']\n",
      "\n",
      "Top ten words with 'u': ['upon', 'us', 'up', 'use', 'U', 'unto', 'Upon', 'under', 'Unless', 'Under']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shakespeareFreqDist = nltk.probability.FreqDist(shakespeareNLTKText)\n",
    "\n",
    "def startsWithA(word):\n",
    "    return re.search(f\"^[Aa]\", word) != None\n",
    "\n",
    "shakespeareTopTenWordsWithA = list(filter(startsWithA, shakespeareFreqDist))[:10]\n",
    "\n",
    "def startsWithE(word):\n",
    "    return re.search(f\"^[Ee]\", word) != None\n",
    "\n",
    "shakespeareTopTenWordsWithE = list(filter(startsWithE, shakespeareFreqDist))[:10]\n",
    "\n",
    "def startsWithI(word):\n",
    "    return re.search(f\"^[Ii]\", word) != None\n",
    "\n",
    "shakespeareTopTenWordsWithI = list(filter(startsWithI, shakespeareFreqDist))[:10]\n",
    "\n",
    "def startsWithO(word):\n",
    "    return re.search(f\"^[Oo]\", word) != None\n",
    "\n",
    "shakespeareTopTenWordsWithO = list(filter(startsWithO, shakespeareFreqDist))[:10]\n",
    "\n",
    "def startsWithU(word):\n",
    "    return re.search(f\"^[Uu]\", word) != None\n",
    "\n",
    "shakespeareTopTenWordsWithU = list(filter(startsWithU, shakespeareFreqDist))[:10]\n",
    "\n",
    "print(f\"Top ten words with 'a': {shakespeareTopTenWordsWithA}\\n\")\n",
    "print(f\"Top ten words with 'e': {shakespeareTopTenWordsWithE}\\n\")\n",
    "print(f\"Top ten words with 'i': {shakespeareTopTenWordsWithI}\\n\")\n",
    "print(f\"Top ten words with 'o': {shakespeareTopTenWordsWithO}\\n\")\n",
    "print(f\"Top ten words with 'u': {shakespeareTopTenWordsWithU}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aab02b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "6. A stemmed version of the longest sentence (extracted above in 3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d487c26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stemmed version of the longest sentence (but with a space around each punctuation):\n",
      "\n",
      "pro , ye elv of hill , brook , stand lake , and grove ; and ye that on , the sand with printless foot do chase the eb neptun , and do fli him when he come back ; you demi-puppet that by moonshin do the green sour ringlet make , whereoftkeewenotbit ; andyouwhosepastim is to make midnight mushroom , that rejoic to hear the solemn curfew ; by whose aid , — weak master thou^ ye be , — i have bedimm ’ d thenoontidesun , call ’ dforththemutin wind , and ’ twixt the green sea and the azur vault set roar war : to the dread rattl thunder have i given fire , and rift jove ’ s stout oak with hi own bolt : the strong-bas promontori have i made shake : and by the spur pluck ’ d up the pine and cedar : grave , at my command , have wake their sleeper , ope , and let them forth by my so potent art .\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "shakespeareLongestSentenceList = []\n",
    "\n",
    "for w in word_tokenize(shakespeareLongestSentence):\n",
    "    shakespeareLongestSentenceList.append(ps.stem(w))\n",
    "\n",
    "shakespeareStemmedSentence = \" \".join(shakespeareLongestSentenceList)\n",
    "    \n",
    "print(\"The stemmed version of the longest sentence (but with a space around each punctuation):\\n\")\n",
    "\n",
    "print(shakespeareStemmedSentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2184d814",
   "metadata": {},
   "source": [
    "## Subcorpus 2: PBS News Transcripts\n",
    "\n",
    "The text is extracted from 1,000 news videos from PBS News Hour and Washington Week, available at https://www.zerotohero.ca/zh/en/show/talk/293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "07a94913",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/news-1000.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cw/nn79qnws6w52_1y8mnsxnsqh0000gn/T/ipykernel_53268/1141218673.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Grab the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnewsFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/news-1000.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnewsText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewsFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(len(newsText))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(set(newsText))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/news-1000.txt'"
     ]
    }
   ],
   "source": [
    "# Grab the text\n",
    "newsFile = open(\"data/news-1000.txt\", \"r\")\n",
    "newsText = newsFile.read()\n",
    "#print(len(newsText))\n",
    "#print(set(newsText))\n",
    "# print(len(set(newsText))\n",
    "\n",
    "# Grab the text\n",
    "comptonFile = open(\"data/straight-outta-compton.txt\", \"r\")\n",
    "comptonText = comptonFile.read()\n",
    "comptonTokenized = nltk.word_tokenize(comptonText)\n",
    "print(len(comptonText))\n",
    "print(len(set(comptonTokenized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cab10f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
