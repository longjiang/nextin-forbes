{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "72345ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be929ed",
   "metadata": {},
   "source": [
    "## Subcorpus 1: The complete works of William Shakespeare\n",
    "\n",
    "The text is downloaded in .txt format from archive.org: \n",
    "https://archive.org/details/completeworksofw00shakrich\n",
    "\n",
    "The file is truncated to include only the first 9,848 lines because we have slow laptops. :-("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b5abc45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text\n",
    "shakespeareFile = open(\"data/literature-shakespeare-trunc.txt\", \"r\")\n",
    "shakespeareText = shakespeareFile.read()\n",
    "shakespeareTokenized = word_tokenize(shakespeareText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23209c",
   "metadata": {},
   "source": [
    "1. The length (in words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8ff594d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49495\n"
     ]
    }
   ],
   "source": [
    "shakespeareTokens = len(shakespeareTokenized)\n",
    "print(shakespeareTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe18df3",
   "metadata": {},
   "source": [
    "2. The lexical diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e58dbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13181129407010808\n"
     ]
    }
   ],
   "source": [
    "shakespeareTypes = len(set(shakespeareTokenized))\n",
    "shakespeareLexDiversity = shakespeareTypes / shakespeareTokens\n",
    "print(shakespeareLexDiversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c908eb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "3. The longest sentence (type the sentence and also give the number of words). Hint: look at the Gutenberg part of Section 2.1 in NLTK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b5f369da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest 'sentence' is:\n",
      "\n",
      "\n",
      "Pro, Ye elves of hills, brooks, standing lakes, \n",
      "and groves; \n",
      "\n",
      "And ye that on, the sands with printless foot \n",
      "Do chase the ebbing Neptune, and do fly him \n",
      "When he comes back; you demi-puppets that \n",
      "By moonshine do the green sour ringlets make, \n",
      "Whereoftkeewenotbites;andyouwhosepastime \n",
      "Is to make midnight mushrooms, that rejoice \n",
      "To hear the solemn curfew; by whose aid, — \n",
      "Weak masters thou^ ye be,— I haVe bedimm’d \n",
      "Thenoontidesun,call’dforththemutinous winds, \n",
      "And ’twixt the green sea and the azured vault \n",
      "Set roaring war: to the dread rattling thunder \n",
      "Have I given fire, and rifted Jove’s stout oak \n",
      "With his own bolt: the strong-based promontory \n",
      "Have I made shake: and by the spurs pluck’d up \n",
      "The pine and cedar: graves, at my command, \n",
      "Have waked their sleepers, oped, and let them \n",
      "forth \n",
      "\n",
      "By my so potent art.\n",
      "\n",
      "\n",
      "\n",
      "The sentence has 173 words.\n"
     ]
    }
   ],
   "source": [
    "shakespeareSentences = nltk.sent_tokenize(shakespeareText)\n",
    "word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "print(\"The longest 'sentence' is:\\n\\n\")\n",
    "shakespeareLongestSentence = max(shakespeareSentences, key=word_count)\n",
    "print(shakespeareLongestSentence)\n",
    "print(\"\\n\\n\")\n",
    "print(f\"The sentence has {word_count(shakespeareLongestSentence)} words.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ce2c7",
   "metadata": {},
   "source": [
    "\n",
    "4. The top collocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9fbc1654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWO GENTLEMEN; thou art; Sir Proteus; thou hast; Sir Thurio; thou\n",
      "canst; Scene I.—; Sir Valentine; Sir John; Master Page; thou beest;\n",
      "widow Dido; Thou liest; Wilt thou; pray thee; PERSONS REPRESENTED;\n",
      "Pro- teus; John Falstaff; Thou hast; Dost thou\n"
     ]
    }
   ],
   "source": [
    "shakespeareNLTKText = nltk.Text(shakespeareTokenized)\n",
    "shakespeareNLTKText.collocations(num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42092de9",
   "metadata": {},
   "source": [
    "5. The top ten words that start with each of the vowels (involves using FreqDist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2e61cb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'a',\n",
       " 'And',\n",
       " 'as',\n",
       " 'are',\n",
       " 'all',\n",
       " 'at',\n",
       " 'am',\n",
       " 'A',\n",
       " 'Ant',\n",
       " 'As',\n",
       " 'an',\n",
       " 'Ay',\n",
       " 'art',\n",
       " 'Ariel',\n",
       " 'again',\n",
       " 'Alon',\n",
       " 'any',\n",
       " 'away',\n",
       " 'Ari',\n",
       " 'An',\n",
       " 'after',\n",
       " 'All',\n",
       " 'another',\n",
       " 'At',\n",
       " 'act',\n",
       " 'Aside',\n",
       " 'air',\n",
       " 'Antonio',\n",
       " 'ACT',\n",
       " 'Are',\n",
       " 'against',\n",
       " 'asleep',\n",
       " 'about',\n",
       " 'Art',\n",
       " 'Alas',\n",
       " 'above',\n",
       " 'ay',\n",
       " 'Adr',\n",
       " 'alone',\n",
       " 'attend',\n",
       " 'age',\n",
       " 'along',\n",
       " 'answer',\n",
       " 'awake',\n",
       " 'almost',\n",
       " 'always',\n",
       " 'anger',\n",
       " 'ask',\n",
       " 'advice',\n",
       " 'awhile',\n",
       " 'Alonso',\n",
       " 'Against',\n",
       " 'arms',\n",
       " 'alive',\n",
       " 'Another',\n",
       " 'afeard',\n",
       " 'amends',\n",
       " 'ass',\n",
       " 'Adrian',\n",
       " 'aboard',\n",
       " 'ashore',\n",
       " 'Awake',\n",
       " 'aU',\n",
       " 'appears',\n",
       " 'Amen',\n",
       " 'attended',\n",
       " 'already',\n",
       " 'affairs',\n",
       " 'afterwards',\n",
       " 'assist',\n",
       " 'advantage',\n",
       " 'afraid',\n",
       " 'amazement',\n",
       " 'aught',\n",
       " 'ambition',\n",
       " 'Alack',\n",
       " 'affections',\n",
       " 'aside',\n",
       " 'angry',\n",
       " 'Although',\n",
       " 'ague',\n",
       " 'adore',\n",
       " 'agamst',\n",
       " 'abroad',\n",
       " 'Alonzo',\n",
       " 'aid',\n",
       " 'Asufe',\n",
       " 'According',\n",
       " 'Apartment',\n",
       " 'ale',\n",
       " 'access',\n",
       " 'Anne',\n",
       " 'airy',\n",
       " 'a-hold',\n",
       " 'ail',\n",
       " 'assurance',\n",
       " 'advance',\n",
       " 'auspicious',\n",
       " 'Approach',\n",
       " 'article',\n",
       " 'afire',\n",
       " 'Argier',\n",
       " 'abhorr',\n",
       " 'abide',\n",
       " 'airs',\n",
       " 'angels',\n",
       " 'assure',\n",
       " 'aye',\n",
       " 'ancient',\n",
       " 'apes',\n",
       " 'afore',\n",
       " 'Aim',\n",
       " 'Anf',\n",
       " 'approach',\n",
       " 'appear',\n",
       " 'April',\n",
       " 'aged',\n",
       " 'action',\n",
       " 'After',\n",
       " 'abuse',\n",
       " 'accidents',\n",
       " 'adieu',\n",
       " 'as—',\n",
       " 'advised',\n",
       " 'applaud',\n",
       " 'affected',\n",
       " 'Away',\n",
       " 'able',\n",
       " 'ale-house',\n",
       " 'among',\n",
       " 'also',\n",
       " 'About',\n",
       " 'Armigero',\n",
       " 'answered',\n",
       " 'attending',\n",
       " 'aground',\n",
       " 'authority',\n",
       " 'arid',\n",
       " 'acre',\n",
       " 'allay',\n",
       " 'ait',\n",
       " 'attentive',\n",
       " 'abysm',\n",
       " 'arts',\n",
       " \"attead'st\",\n",
       " 'Awaked',\n",
       " 'Absolute',\n",
       " 'annual',\n",
       " 'alas',\n",
       " 'army',\n",
       " 'andi',\n",
       " 'appointed',\n",
       " 'arise',\n",
       " 'arrived',\n",
       " 'accident',\n",
       " 'angle',\n",
       " 'arriv',\n",
       " 'Aru',\n",
       " 'apparition',\n",
       " 'Abhorred',\n",
       " 'aches',\n",
       " 'AMEL',\n",
       " 'Allaying',\n",
       " 'Asiofe',\n",
       " 'Afira',\n",
       " 'affection',\n",
       " 'Asofe',\n",
       " 'acorn',\n",
       " 'advocate',\n",
       " 'AJl',\n",
       " 'Aerian',\n",
       " 'AJon',\n",
       " 'Aton',\n",
       " 'advantageous',\n",
       " 'asthey',\n",
       " 'Africk',\n",
       " 'apple',\n",
       " 'African',\n",
       " 'admit',\n",
       " 'abundance',\n",
       " 'adven-',\n",
       " 'Ambition',\n",
       " 'amply',\n",
       " 'advancement',\n",
       " 'apart',\n",
       " 'Alom',\n",
       " 'Aswic',\n",
       " 'adders',\n",
       " 'aHve',\n",
       " 'AJas',\n",
       " 'acquaints',\n",
       " 'Anon',\n",
       " 'anon',\n",
       " 'abominable',\n",
       " 'Admir',\n",
       " 'admiration',\n",
       " 'Any',\n",
       " 'Am',\n",
       " 'appertainmg',\n",
       " 'agood',\n",
       " 'Awel',\n",
       " 'andnomore',\n",
       " 'afternoon',\n",
       " 'aeoid',\n",
       " 'andflotU',\n",
       " 'ache',\n",
       " 'attach',\n",
       " 'ANT',\n",
       " 'actions',\n",
       " 'Atom',\n",
       " 'Alan',\n",
       " 'Arabia',\n",
       " 'Asilde',\n",
       " 'Aatcfe',\n",
       " 'Alon.',\n",
       " 'austerely',\n",
       " 'acqmsition',\n",
       " 'aspersion',\n",
       " 'abstemious',\n",
       " 'Abates',\n",
       " 'ardour',\n",
       " 'Afasque',\n",
       " 'Andfiatmeadsthatch',\n",
       " 'arch',\n",
       " 'activ',\n",
       " 'amain',\n",
       " 'acres',\n",
       " 'arrows',\n",
       " 'Answer',\n",
       " 'August',\n",
       " 'Asote',\n",
       " 'avoid',\n",
       " 'actors',\n",
       " 'agrin',\n",
       " 'Advanced',\n",
       " 'apporel',\n",
       " 'ain',\n",
       " 'auctions',\n",
       " 'andyouwhosepastime',\n",
       " 'azured',\n",
       " 'abjure',\n",
       " 'apace',\n",
       " 'approaching',\n",
       " 'attire',\n",
       " 'affiction',\n",
       " 'Asirfe',\n",
       " 'admire',\n",
       " 'attendants',\n",
       " 'Arise',\n",
       " 'acquaintance',\n",
       " 'amazedly',\n",
       " 'awaked',\n",
       " 'Asitfe',\n",
       " 'Acknowledge',\n",
       " 'afar',\n",
       " 'assaults',\n",
       " 'Agent',\n",
       " 'aSection',\n",
       " 'absence',\n",
       " 'astray',\n",
       " 'agaiUj',\n",
       " 'angnly',\n",
       " 'Amd',\n",
       " 'although',\n",
       " 'achieved',\n",
       " 'Attends',\n",
       " 'Al-',\n",
       " 'agent',\n",
       " 'accords',\n",
       " 'answers',\n",
       " 'apartment',\n",
       " 'Ah',\n",
       " 'arc',\n",
       " 'account',\n",
       " 'affec-',\n",
       " 'Asvde',\n",
       " 'athousand',\n",
       " 'AprottyperiodlWeE',\n",
       " 'angel-like',\n",
       " 'athiagithad',\n",
       " 'according',\n",
       " 'Acxn',\n",
       " 'alter',\n",
       " 'andis',\n",
       " 'ame',\n",
       " 'always—',\n",
       " 'Ask',\n",
       " 'Aiming',\n",
       " 'Ail',\n",
       " 'Ante-room',\n",
       " 'aim',\n",
       " 'ascend',\n",
       " 'aimed',\n",
       " 'Adieu',\n",
       " 'affect',\n",
       " 'agone',\n",
       " 'after-love',\n",
       " 'aloft',\n",
       " 'apparent',\n",
       " 'anchoring',\n",
       " 'adventure',\n",
       " 'Advise',\n",
       " 'aspire',\n",
       " 'ACTln',\n",
       " 'anthem',\n",
       " 'abridge',\n",
       " 'atlarge',\n",
       " 'an-',\n",
       " 'advan-',\n",
       " 'altar',\n",
       " 'ance',\n",
       " 'afterward',\n",
       " 'adversity',\n",
       " 'an^hing',\n",
       " 'awful',\n",
       " 'alhed',\n",
       " 'ah',\n",
       " 'Already',\n",
       " 'allycholly',\n",
       " 'admired',\n",
       " 'ashamed',\n",
       " 'Assure',\n",
       " 'attends',\n",
       " 'accomplish',\n",
       " 'abode',\n",
       " 'acquainted',\n",
       " 'ado',\n",
       " 'augury',\n",
       " 'Almost',\n",
       " 'Asif',\n",
       " 'a-good',\n",
       " 'Ariadne',\n",
       " 'acted',\n",
       " 'auburn',\n",
       " 'ador',\n",
       " 'Abheu-',\n",
       " 'amen',\n",
       " 'abbey',\n",
       " 'Asicfe',\n",
       " 'As^e',\n",
       " 'Aride',\n",
       " 'ami',\n",
       " 'approacheth',\n",
       " 'AsMe',\n",
       " 'ather',\n",
       " 'approved',\n",
       " 'adl',\n",
       " 'appeas',\n",
       " 'aiin',\n",
       " 'asham',\n",
       " 'ancestry',\n",
       " 'Ac',\n",
       " 'adjacent',\n",
       " 'ancestors',\n",
       " 'agrees',\n",
       " 'atone-',\n",
       " 'Abraham',\n",
       " 'Aone',\n",
       " 'at-',\n",
       " 'auca/',\n",
       " 'affectations',\n",
       " 'a-']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeareFreqDist = nltk.probability.FreqDist(shakespeareNLTKText)\n",
    "\n",
    "def startsWithVowel(word):\n",
    "    return re.search(\"^[Aa]\", word) != None\n",
    "\n",
    "list(filter(startsWithVowel, shakespeareFreqDist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aab02b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "6. A stemmed version of the longest sentence (extracted above in 3). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6f2e4",
   "metadata": {},
   "source": [
    "## Subcorpus 2: PBS News Transcripts\n",
    "\n",
    "The text is extracted from 1,000 news videos from PBS News Hour and Washington Week, available at https://www.zerotohero.ca/zh/en/show/talk/293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07a94913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185621\n",
      "5717\n"
     ]
    }
   ],
   "source": [
    "# Grab the text\n",
    "newsFile = open(\"data/news-1000.txt\", \"r\")\n",
    "newsText = newsFile.read()\n",
    "#print(len(newsText))\n",
    "#print(set(newsText))\n",
    "# print(len(set(newsText))\n",
    "\n",
    "# Grab the text\n",
    "comptonFile = open(\"data/straight-outta-compton.txt\", \"r\")\n",
    "comptonText = comptonFile.read()\n",
    "comptonTokenized = nltk.word_tokenize(comptonText)\n",
    "print(len(comptonText))\n",
    "print(len(set(comptonTokenized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c2feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
