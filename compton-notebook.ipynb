{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a9a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.collocations import *\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda3b5df",
   "metadata": {},
   "source": [
    "## Subcorpus 3: Straight Outta Compton\n",
    "\n",
    "This is Straight Outta Compton Screenplay by Jonathan Herman and Andrea Berloff, downloaded from https://archive.org/details/StraightOuttaComptonScreenplayByJonathanHermanAndAndreaBerloff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd0bc104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text\n",
    "comptonFile = open(\"data/straight-outta-compton.txt\", \"r\")\n",
    "comptonText = comptonFile.read()\n",
    "comptonTokenized = word_tokenize(comptonText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23209c",
   "metadata": {},
   "source": [
    "1. The length (in words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ff594d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40887\n"
     ]
    }
   ],
   "source": [
    "comptonTokens = len(comptonTokenized)\n",
    "print(comptonTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe18df3",
   "metadata": {},
   "source": [
    "2. The lexical diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e58dbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1398243940616822\n"
     ]
    }
   ],
   "source": [
    "comptonTypes = len(set(comptonTokenized))\n",
    "comptonLexDiversity = comptonTypes / comptonTokens\n",
    "print(comptonLexDiversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c908eb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "3. The longest sentence (type the sentence and also give the number of words). Hint: look at the Gutenberg part of Section 2.1 in NLTK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "494007bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest 'sentence' is:\n",
      "\n",
      "\n",
      "PROD #02443 \n",
      "\n",
      "\n",
      "Director: F. Gary Gray \n",
      "Producer: Ice Cube \n",
      "Producer: Tomica Woods-Wright \n",
      "Producer: Matt Alvarez \n",
      "Producer: F. Gary Gray \n",
      "Producer: Scott Bernstein \n",
      "Producer: Dr. Dre \n",
      "Executive Producer: Adam Merims \n",
      "\n",
      "\n",
      "STRAIGHT OUTTA COMPTON \n",
      "\n",
      "\n",
      "Screenplay by \n",
      "\n",
      "Jonathan Herman and Andrea Berloff \n",
      "Story by \n",
      "\n",
      "S. Leigh Savidge & Alan Wenkus and Andrea Berloff \n",
      "\n",
      "\n",
      "Notice : \n",
      "\n",
      "This material is the property of Straight Outta LLC (A wholly \n",
      "owned subsidiary of Universal City Studios, Inc.) and is intended \n",
      "and restricted solely for studio use by studio personnel.\n",
      "\n",
      "\n",
      "\n",
      "The sentence has 95 words.\n"
     ]
    }
   ],
   "source": [
    "comptonSentences = nltk.sent_tokenize(comptonText)\n",
    "word_count = lambda sentence: len(nltk.word_tokenize(sentence))\n",
    "print(\"The longest 'sentence' is:\\n\\n\")\n",
    "comptonLongestSentence = max(comptonSentences, key=word_count)\n",
    "print(comptonLongestSentence)\n",
    "print(\"\\n\\n\")\n",
    "print(f\"The sentence has {word_count(comptonLongestSentence)} words.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ce2c7",
   "metadata": {},
   "source": [
    "\n",
    "4. The top collocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc3461da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRYAN TURNER; LOS ANGELES; Death Row; AUDIO ACHIEVEMENTS; TORRANCE\n",
      "COP; STRAIGHT OUTTA; OUTTA COMPTON; TOUR BUS; ACHIEVEMENTS STUDIO;\n",
      "MOMENTS LATER; LENCH MOB; Jerry Heller; JIMMY IOVINE; n't even; JERRY\n",
      "HELLER; n't believe; n't know; DEATH ROW; Jheri curl; NEW YORK\n"
     ]
    }
   ],
   "source": [
    "comptonNLTKText = nltk.Text(comptonTokenized)\n",
    "comptonNLTKText.collocations(num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42092de9",
   "metadata": {},
   "source": [
    "5. The top ten words that start with each of the vowels (involves using FreqDist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "625b4961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten words with 'a': ['a', 'and', 'at', 'as', 'all', 'about', 'A', 'are', 'And', 'around']\n",
      "\n",
      "Top ten words with 'e': ['Eazy', 'EAZY', 'eyes', 'EXT', 'Eric', 'even', 'each', 'exits', 'ever', 'everything']\n",
      "\n",
      "Top ten words with 'i': ['I', 'in', 'it', 'is', 'INT', 'It', 'into', 'if', 'IN', 'INTO']\n",
      "\n",
      "Top ten words with 'o': ['of', 'on', 'out', 'over', 'off', 'one', 'other', 'ON', 'or', 'OF']\n",
      "\n",
      "Top ten words with 'u': ['up', 'us', 'UP', 'uckin', 'under', 'until', 'Until', 'upon', 'UNIFORM', 'ucka']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comptonFreqDist = nltk.probability.FreqDist(comptonNLTKText)\n",
    "\n",
    "def startsWithA(word):\n",
    "    return re.search(f\"^[Aa]\", word) != None\n",
    "\n",
    "comptonTopTenWordsWithA = list(filter(startsWithA, comptonFreqDist))[:10]\n",
    "\n",
    "def startsWithE(word):\n",
    "    return re.search(f\"^[Ee]\", word) != None\n",
    "\n",
    "comptonTopTenWordsWithE = list(filter(startsWithE, comptonFreqDist))[:10]\n",
    "\n",
    "def startsWithI(word):\n",
    "    return re.search(f\"^[Ii]\", word) != None\n",
    "\n",
    "comptonTopTenWordsWithI = list(filter(startsWithI, comptonFreqDist))[:10]\n",
    "\n",
    "def startsWithO(word):\n",
    "    return re.search(f\"^[Oo]\", word) != None\n",
    "\n",
    "comptonTopTenWordsWithO = list(filter(startsWithO, comptonFreqDist))[:10]\n",
    "\n",
    "def startsWithU(word):\n",
    "    return re.search(f\"^[Uu]\", word) != None\n",
    "\n",
    "comptonTopTenWordsWithU = list(filter(startsWithU, comptonFreqDist))[:10]\n",
    "\n",
    "print(f\"Top ten words with 'a': {comptonTopTenWordsWithA}\\n\")\n",
    "print(f\"Top ten words with 'e': {comptonTopTenWordsWithE}\\n\")\n",
    "print(f\"Top ten words with 'i': {comptonTopTenWordsWithI}\\n\")\n",
    "print(f\"Top ten words with 'o': {comptonTopTenWordsWithO}\\n\")\n",
    "print(f\"Top ten words with 'u': {comptonTopTenWordsWithU}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aab02b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "6. A stemmed version of the longest sentence (extracted above in 3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2aa4639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stemmed version of the longest sentence (but with a space around each punctuation):\n",
      "\n",
      "prod # 02443 director : f. gari gray produc : ice cube produc : tomica woods-wright produc : matt alvarez produc : f. gari gray produc : scott bernstein produc : dr. dre execut produc : adam merim straight outta compton screenplay by jonathan herman and andrea berloff stori by s. leigh savidg & alan wenku and andrea berloff notic : thi materi is the properti of straight outta llc ( a wholli own subsidiari of univers citi studio , inc. ) and is intend and restrict sole for studio use by studio personnel .\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "comptonLongestSentenceList = []\n",
    "\n",
    "for w in nltk.word_tokenize(comptonLongestSentence):\n",
    "    comptonLongestSentenceList.append(ps.stem(w))\n",
    "\n",
    "comptonStemmedSentence = \" \".join(comptonLongestSentenceList)\n",
    "    \n",
    "print(\"The stemmed version of the longest sentence (but with a space around each punctuation):\\n\")\n",
    "\n",
    "print(comptonStemmedSentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
